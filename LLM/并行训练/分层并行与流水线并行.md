# 从 简单的分层并行 到 流水线并行

> paper: [Gpipe](https://arxiv.org/abs/1811.06965v5)

## 一、分层并行

当我们的模型较大，一块GPU上放不下时，可以使用这种方式。
- 例如模型有32层，每块GPU只能放下8层
    - **GPU0**上放`0-7`
    - **GPU1**上放`8-15`
    - **GPU2**上放`16-23`
    - **GPU3**上放`24-31`

- 模型训练时，示意图如下:

    ![simple.png](../jpgs/simple.png)

    > 在$t_0$时刻，GPU0做forward；t1时刻，GPU1做forward...  
    > 在$t_4$时刻，GPU0做backward；t5时刻，GPU1做backward...  
    > 最后的$t_8$时刻，所有的GPU统一更新梯度  
    > $t_0$至$t_7$，每一时刻只有一个GPU在运行，资源比较浪费

## 二、流水线并行
流水线并行，是在上面的基础上，引入数据并行。即把原先的一个batch，再划分成若干个mini-batch，送入GPU进行训练

- 示意图如下:

    ![Gpipe.png](../jpgs/Gpipe.png)

- 上图中我们有4个GPU，每个batch划分成了4个mini-batch
> 假设我们有K个GPU，每个batch划分成了M个mini-batch  
> Gpipe通过实验证明，当M>=4K时，图中的bubble部分占比很小，可忽略不计
