# 线性代数(linear algebra)

## 一、基础概念
### 1. 向量(vector)
> 注: 默认为列向量

$$
\vec{v} \in \R^{n} = 
\begin{pmatrix}
v_{1}\\
v_{2}\\
\vdots\\
v_{n}
\end{pmatrix}
$$

### 2. 矩阵(matrix)
- 一般形式
$$
\mathbf A \in \R^{m*n} =  
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix}
$$

- 对角矩阵(diagonal matrix)
> 主对角线上有值，其余元素均为0

$$
\Sigma \in \R^{m*n} =
\begin{pmatrix}
a_{11} & 0 & 0 & 0 \\
0 & a_{22} & 0 & 0 \\
0 & 0 & a_{33} & 0 \\
0 & 0 & 0 & a_{44} \\
0 & 0 & 0 & 0 \\
\end{pmatrix}
$$

- 单位矩阵(identity matrix)
$$
\mathbf E \in \R^{n*n} = \mathbf I =  
\begin{pmatrix}
1 & 0 & \cdots & 0 \\
0 & 1 & 0 & \vdots \\
\vdots & 0 & \ddots & \\
0 & \cdots & & 1 \\
\end{pmatrix}
$$

## 二、向量与向量之间的运算
> 两个列向量: $\vec{u}, \vec{v} \in \R^{n}, 它们之间的夹角记为\theta$
### 1. 内积(inner product)、点积
$$
\begin{aligned}
    u \cdot v & = <u,v> \\
    & = |u|*|v|*\cos \theta \\
    & = u^{T} v \\
    & = (u_{1}, u_{2}, \cdots, u_{n})
        \begin{pmatrix}
            v_{1}\\
            v_{2}\\
            \vdots\\
            v_{n}
        \end{pmatrix} \\
    & = \sum\limits_{i=1}^n u_{i}v_{i}
\end{aligned}
$$
### 2. 外积(outer product)、kronecker积
$$
\begin{aligned}
    u \otimes v & = u v^{T} \\
    & = 
        \begin{pmatrix}
            u_{1}\\
            u_{2}\\
            \vdots\\
            u_{n}
        \end{pmatrix}
        (v_{1}, v_{2}, \cdots, v_{n}) \\
    & = 
        \begin{pmatrix}
            u_{1}v_{1} & u_{1}v_{2} & \cdots & u_{1}v_{n}\\
            u_{2}v_{1} & u_{2}v_{2} & \cdots & u_{2}v_{n}\\
            \vdots & \vdots & \ddots & \vdots\\
            u_{n}v_{1} & u_{n}v_{2} & \cdots & u_{n}v_{n}\\
        \end{pmatrix}
\end{aligned}
$$
### 3. 叉积、向量积
$$
\begin{aligned}
    u \times v & = 
    \begin{vmatrix}
        i & j & k\\
        u_{1} & u_{2} & u_{3}\\
        v_{1} & v_{2} & v_{3}\\
    \end{vmatrix} \\
    & = i
    \begin{vmatrix}
        u_{2} & u_{3}\\
        v_{2} & v_{3}\\
    \end{vmatrix}
    - j
    \begin{vmatrix}
        u_{1} & u_{3}\\
        v_{1} & v_{3}\\
    \end{vmatrix}
    + k
    \begin{vmatrix}
        u_{1} & u_{2}\\
        v_{1} & v_{2}\\
    \end{vmatrix} 
\end{aligned}
$$

## 三、矩阵与向量之间的运算
$$
\begin{aligned}
    \mathbf A \cdot \vec{v} & = 
    \begin{pmatrix}
        a_{11} & a_{12} & \cdots & a_{1n}\\
        a_{21} & a_{22} & \cdots & a_{2n}\\
        \vdots & \vdots & \ddots & \vdots\\
        a_{m1} & a_{m2} & \cdots & a_{mn}
    \end{pmatrix}
    \begin{pmatrix}
        v_{1}\\
        v_{2}\\
        \vdots\\
        v_{n}
    \end{pmatrix}\\
    & 第一种分解法，将矩阵A看作m个行向量:\\
    & = 
    \begin{pmatrix}
        ( & a_{11} & a_{12} & \cdots & a_{1n} & )\\
        ( & a_{21} & a_{22} & \cdots & a_{2n} & )\\
        ( & \vdots & \vdots & \ddots & \vdots & )\\
        ( & a_{m1} & a_{m2} & \cdots & a_{mn} & )
    \end{pmatrix}
    \begin{pmatrix}
        v_{1}\\
        v_{2}\\
        \vdots\\
        v_{n}
    \end{pmatrix}\\
    & = 
    \begin{pmatrix}
        \alpha_{1}\\
        \alpha_{2}\\
        \vdots\\
        \alpha_{m}
    \end{pmatrix}
    \cdot \vec{v}\\
    & =
    \begin{pmatrix}
        \alpha_{1} \cdot \vec{v}\\
        \alpha_{2} \cdot \vec{v}\\
        \vdots\\
        \alpha_{m} \cdot \vec{v}
    \end{pmatrix}\\
    & = 
    \begin{pmatrix}
        \sum\limits_{i=1}^n a_{1i}v_{i}\\
        \sum\limits_{i=1}^n a_{2i}v_{i}\\
        \vdots\\
        \sum\limits_{i=1}^n a_{mi}v_{i}\\
    \end{pmatrix}\\
    & 第二种分解法，将矩阵A看作n个列向量:\\
    & = 
    \left (
        \begin{pmatrix}
            a_{11}\\
            a_{21}\\
            \vdots\\
            a_{m1}
        \end{pmatrix}
        \begin{pmatrix}
            a_{12}\\
            a_{22}\\
            \vdots\\
            a_{m2}
        \end{pmatrix}
        \cdots
        \begin{pmatrix}
            a_{1n}\\
            a_{2n}\\
            \vdots\\
            a_{mn}
        \end{pmatrix}
    \right )
    \begin{pmatrix}
        v_{1}\\
        v_{2}\\
        \vdots\\
        v_{n}
    \end{pmatrix}\\
    & = (\alpha_{1}, \alpha_{1}, \cdots, \alpha_{n})
        \begin{pmatrix}
            v_{1}\\
            v_{2}\\
            \vdots\\
            v_{n}
        \end{pmatrix}\\
    & = \alpha_{1} v_{1} + \alpha_{2} v_{2} + \cdots + \alpha_{n} v_{n}\\
    & =  \begin{pmatrix}
          a_{11}\\
          a_{21}\\
          \vdots\\
          a_{m1}
        \end{pmatrix} v_1
      + \begin{pmatrix}
          a_{12}\\
          a_{22}\\
          \vdots\\
          a_{m2}
        \end{pmatrix} v_2
      + \cdots
      + \begin{pmatrix}
          a_{1n}\\
          a_{2n}\\
          \vdots\\
          a_{mn}
        \end{pmatrix} v_n\\
    & = \sum\limits_{i=1}^n
        \begin{pmatrix}
            a_{1i}\\
            a_{2i}\\
            \vdots\\
            a_{mi}
        \end{pmatrix} v_i
\end{aligned}
$$

## 四、矩阵与矩阵之间的运算
$$
\begin{aligned}
    \mathbf A^{m*n} \cdot \mathbf B^{n*k} & = 
    \begin{pmatrix}
        a_{11} & a_{12} & \cdots & a_{1n}\\
        a_{21} & a_{22} & \cdots & a_{2n}\\
        \vdots & \vdots & \ddots & \vdots\\
        a_{m1} & a_{m2} & \cdots & a_{mn}
    \end{pmatrix}
    \begin{pmatrix}
        b_{11} & b_{12} & \cdots & b_{1k}\\
        b_{21} & b_{22} & \cdots & b_{2k}\\
        \vdots & \vdots & \ddots & \vdots\\
        b_{n1} & b_{n2} & \cdots & b_{nk}
    \end{pmatrix}\\
    & 第一种分解法:\\
    & 将A看作m个行向量，B看作k个列向量\\
    & = 
    \begin{pmatrix}
        ( & a_{11} & a_{12} & \cdots & a_{1n} & )\\
        ( & a_{21} & a_{22} & \cdots & a_{2n} & )\\
        ( & \vdots & \vdots & \ddots & \vdots & )\\
        ( & a_{m1} & a_{m2} & \cdots & a_{mn} & )
    \end{pmatrix}
    \left (
        \begin{pmatrix}
            b_{11}\\
            b_{21}\\
            \vdots\\
            b_{n1}
        \end{pmatrix}
        \begin{pmatrix}
            b_{12}\\
            b_{22}\\
            \vdots\\
            b_{n2}
        \end{pmatrix}
        \cdots
        \begin{pmatrix}
            b_{1k}\\
            b_{2k}\\
            \vdots\\
            b_{nk}
        \end{pmatrix}
    \right )\\
    & = 
        \begin{pmatrix}
            \alpha_{1}\\
            \alpha_{2}\\
            \vdots\\
            \alpha_{m}
        \end{pmatrix}
        (\beta_{1}, \beta_{1}, \cdots, \beta_{k})\\
    & = \alpha \otimes \beta\\
    & = 
        \begin{pmatrix}
            \alpha_{1}\beta_{1} & \alpha_{1}\beta_{2} & \cdots & \alpha_{1}\beta_{k}\\
            \alpha_{2}\beta_{1} & \alpha_{2}\beta_{2} & \cdots & \alpha_{2}\beta_{k}\\
            \vdots & \vdots & \ddots & \vdots\\
            \alpha_{m}\beta_{1} & \alpha_{m}\beta_{2} & \cdots & \alpha_{m}\beta_{k}\\
        \end{pmatrix}\\
    & = 
    \begin{pmatrix}
        \sum\limits_{i=1}^n a_{1i}b_{i1} & \sum\limits_{i=1}^n a_{1i}b_{i2} & \cdots & \sum\limits_{i=1}^n a_{1i}b_{ik}\\
        \sum\limits_{i=1}^n a_{2i}b_{i1} & \sum\limits_{i=1}^n a_{2i}b_{i2} & \cdots & \sum\limits_{i=1}^n a_{2i}b_{ik}\\
        \vdots\\
        \sum\limits_{i=1}^n a_{mi}b_{i1} & \sum\limits_{i=1}^n a_{mi}b_{i2} & \cdots & \sum\limits_{i=1}^n a_{mi}b_{ik}\\
    \end{pmatrix}\\
    & 第二种分解法:\\
    & 将A看作n个列向量，B看作n个行向量\\
    & = 
    \left (
        \begin{pmatrix}
            a_{11}\\
            a_{21}\\
            \vdots\\
            a_{m1}
        \end{pmatrix}
        \begin{pmatrix}
            a_{12}\\
            a_{22}\\
            \vdots\\
            a_{m2}
        \end{pmatrix}
        \cdots
        \begin{pmatrix}
            a_{1n}\\
            a_{2n}\\
            \vdots\\
            a_{mn}
        \end{pmatrix}
    \right )
    \begin{pmatrix}
        ( & b_{11} & b_{12} & \cdots & b_{1k} & )\\
        ( & b_{21} & b_{22} & \cdots & b_{2k} & )\\
        ( & \vdots & \vdots & \ddots & \vdots & )\\
        ( & b_{n1} & b_{n2} & \cdots & b_{nk} & )
    \end{pmatrix}\\
    & = (\alpha_{1}, \alpha_{2}, \cdots, \alpha_{n})
        \begin{pmatrix}
            \beta_{1}\\
            \beta_{2}\\
            \vdots\\
            \beta_{n}
        \end{pmatrix}\\
    & = \alpha \cdot \beta\\
    & = \sum\limits_{i=1}^n \alpha_{i}\ \otimes \beta_{i}\\
    & = \sum\limits_{i=1}^n
        \begin{pmatrix}
          a_{1i}\\
          a_{2i}\\
          \vdots\\
          a_{mi}
        \end{pmatrix}
        (b_{i1}, b_{i2}, \cdots, b_{ik})\\
    & =  \begin{pmatrix}
          a_{11}\\
          a_{21}\\
          \vdots\\
          a_{m1}
        \end{pmatrix}
        (b_{11}, b_{12}, \cdots, b_{1k})
      + \begin{pmatrix}
          a_{12}\\
          a_{22}\\
          \vdots\\
          a_{m2}
        \end{pmatrix}
        (b_{21}, b_{22}, \cdots, b_{2k})
      + \cdots
      + \begin{pmatrix}
          a_{1n}\\
          a_{2n}\\
          \vdots\\
          a_{mn}
        \end{pmatrix}
        (b_{n1}, b_{n2}, \cdots, b_{nk})\\
\end{aligned}
$$

## 五、矩阵分解
### 1. 特征值分解
> 特征值与特征向量  
  对于一个方阵$\bf A$，若$\bf A \vec{x} = \lambda \vec{x}$，则有$\lambda$为特征值，$\vec{x}$为特征向量

  此时矩阵A可分解，有：$A = W \Sigma W^{-1}$

> 若将矩阵W中的n个特征向量标准化，使其满足$w_i^T w_i = 1$  
  此时n个特征向量为标准正交基，满足$W^{T}W=E$，即$W^{T}=W^{-1}$，也说W为酉矩阵

  那么矩阵A也可以写成：$A = W \Sigma W^{T}$

### 2. 奇异值分解
> 并不是所有的矩阵都可以进行特征值分解，例如一个m * n的矩阵A，此时就需要SVD了  
  类似于特征分解，SVD的形式为：$\bf A^{(m*n)} = U^{(m*m)} \Sigma^{(m*n)} V^{T(n*n)}$  
  其中$U、V$均为酉矩阵，即满足$U^T U = E, V^T V = E$
- 接下来看如何求出$U、\Sigma、V$:  
$$
A = U \Sigma V^T \Longrightarrow A^T = V \Sigma^T U^T\\
\Rightarrow
\begin{cases}
    A A^T = U \Sigma V^T V \Sigma^T U^T = U \Sigma \Sigma^T U^T = U \Sigma \Sigma U^T = U \Sigma^2 U^T\\
    A^T A = V \Sigma^T U^T U \Sigma V^T = V \Sigma^T \Sigma V^T = V \Sigma \Sigma V^T = V \Sigma^2 V^T
\end{cases}
$$

由此可见:
- $A A^T$的特征矩阵即为$U$, $U$称为A的左奇异矩阵
- $A^T A$的特征矩阵即为$V$, $V$称为A的右奇异矩阵
- $A A^T$或者$A^T A$的特征值，即为$\Sigma$中各对角元素的平方  
  类似于特征值，$\Sigma$中各对角元素，称为A的奇异值

> 参考链接: https://zhuanlan.zhihu.com/p/29846048
