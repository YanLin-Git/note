# 最大熵模型
> 这部分CS229中没有介绍，参考李航老师的《统计学习方法》

## 1. 预备知识
#### 1.1 最大熵原理
概率模型学习的一个准则，最大熵原理认为:  
学习概率模型时，在所有可能的概率模型中，熵最大的模型，就是最好的模型

#### 1.2 熵、条件熵
1. 假设离散随机变量X的概率分布为P(X)，则熵的计算为:  
$$H(P) = - \sum\limits_x P(x) \log P(x)$$

2. 条件概率分布P(Y|X)的熵为:  
$$H(P) = - \sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x)$$

#### 1.3 经验分布
需要提前计算P(X,Y)、P(X)的经验分布

$$
\tilde{P}(X=x,Y=y) = \frac {\#(X=x, Y=y)} {m} \\
\tilde{P}(X=x) = \frac {\#(X=x)} {m}
$$

> #(X=x,Y=y)表示样本中(x,y)出现的频次  
> #(X=x)表示样本中x出现的频次  
> m为样本容量  

#### 1.4 特征函数
每个特征函数f(x,y)，相当于给模型P(y|x)添加一个约束条件:  
$$\sum\limits_{x,y} \tilde{P}(x) P(y|x) f(x,y) = \sum\limits_{x,y} \tilde{P}(x,y) f(x,y)$$

> 参考 https://www.zhihu.com/question/24094554/answer/1507080982  
> 通俗易懂

## 2. 目标函数
给定n个特征函数，也就是给模型添加n个约束条件  
我们的任务就是: 在n个约束条件下，求解熵最大的模型

**用数学公式表示出来就是**：
$$
\begin{aligned}
    max \quad & H(P) = - \sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x)\\
    s.t. \quad & \sum\limits_{x,y} \tilde{P}(x) P(y|x) f_i(x,y) = \sum\limits_{x,y} \tilde{P}(x,y) f_i(x,y), \quad i=1,2,\cdots,n\\
    & \sum\limits_y P(y|x) = 1
\end{aligned}
$$

**稍微改写一下，方便引入拉格朗日函数**:
$$
\begin{aligned}
    min \quad & -H(P) = \sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x)\\
    s.t. \quad & \sum\limits_{x,y} \tilde{P}(x) P(y|x) f_i(x,y) - \sum\limits_{x,y} \tilde{P}(x,y) f_i(x,y) = 0, \quad i=1,2,\cdots,n\\
    & 1 - \sum\limits_y P(y|x) = 0
\end{aligned}
$$

**相应的拉格朗日函数**:
$$
    L(P,w) = \sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x) + w_0 \left[ 1 - \sum\limits_y P(y|x) \right] + \sum\limits_{i=1}^n w_i \left[ \sum\limits_{x,y} \tilde{P}(x,y) f_i(x,y) - \sum\limits_{x,y} \tilde{P}(x) P(y|x) f_i(x,y) \right]
$$

跟SVM中的**对偶优化问题**类似:  
**原始问题**: 求解$min_{P} \quad max_w \quad L(P,w)$  
可以转化为 求解其**对偶问题**: $max_w \quad min_P \quad L(P,w)$

**求解过程**:
#### 2.1 求解 $min_P \quad L(P,w)$

> 首先把L(P,w)中，跟P(y|x)无关的先忽略掉，化简如下:

$$
    l(P,w) = \sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x) - w_0 \sum\limits_y P(y|x) - \sum\limits_{i=1}^n w_i \left[ \sum\limits_{x,y} \tilde{P}(x) P(y|x) f_i(x,y) \right]
$$

> 再利用$\sum\limits_y = \sum\limits_{x,y} \tilde{P}(x)$，对第二项做个修改

$$
    l(P,w) = \sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x) - w_0 \sum\limits_{x,y} \tilde{P}(x) P(y|x) - \sum\limits_{i=1}^n w_i \left[ \sum\limits_{x,y} \tilde{P}(x) P(y|x) f_i(x,y) \right]
$$

> 最后，第三项 改变下加和顺序

$$
\begin{aligned}
    l(P,w) &= \sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x) - w_0 \sum\limits_{x,y} \tilde{P}(x) P(y|x) - \sum\limits_{x,y} \tilde{P}(x) P(y|x) \left[ \sum\limits_{i=1}^n w_i f_i(x,y) \right] \\
    &= \sum\limits_{x,y} \tilde{P}(x) P(y|x) \left[ \log P(y|x) - w_0 - \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right) \right]
\end{aligned}
$$

这样看起来就简单多了，要使l(P,w)取得最小值，只需要针对每一组可能的取值(x,y)，令下面的子式取得最小值即可:
$$
    \tilde{P}(x) P(y|x) \left[ \log P(y|x) - w_0 - \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right) \right], \quad 记作 \quad l_{x,y}(P,w)
$$

**求偏导**  
$$
\begin{aligned}
    \frac {\partial l_{x,y}(P,w)} {\partial P(y|x)} 
    & = \tilde{P}(x) \left[ \log P(y|x) - w_0 - \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right) \right] + \tilde{P}(x) P(y|x) \frac 1 {P(y|x)} \\
    & = \tilde{P}(x) \left[ \log P(y|x) - w_0 - \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right) + 1 \right]
\end{aligned}
$$

**令偏导数=0**，因为$\tilde{P}(x)$>0，可得:
$$
\begin{aligned}
    & \log P(y|x) - w_0 - \sum\limits_{i=1}^n w_i f_i(x,y) + 1 = 0\\
    \Rightarrow P(y|x) &= exp \left( w_0 + \sum\limits_{i=1}^n w_i f_i(x,y) - 1 \right) \\
    &= \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {exp (1 - w_0)} \\
    &= \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {与x,y取值无关的常量}
\end{aligned}
$$

最后，由于$\sum\limits_y P(y|x) = 1$，可进一步化简得:
$$
\begin{aligned}
    P(y|x) &= \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {\sum\limits_y  exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} \quad (1)\\
    &= \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {与y无关的常量} \\
    &= \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {Z(x)}
\end{aligned}
$$

> 这里Z(x)称为规范化因子  
> $f_i(x,y)$ 是特征函数，$w_i$是特征的权值
- 上面的(1)式就是我们的**最大熵模型**, w为模型中的参数

#### 2.2 求解 $max_w \quad L(w)$

> 为了书写简便，把上面的(1)式，记作$P_w(y|x)$，相应的规范化因子，记作$Z_w(x)$

将$P_w(y|x)$代入到$L(P,w)$中，得到优化目标:
$$
\begin{aligned}
    L(P,w) = \Psi(w) &= \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) \log P_w(y|x) + w_0 \left[ 1 - \sum\limits_y P_w(y|x) \right] + \sum\limits_{i=1}^n w_i \left[ \sum\limits_{x,y} \tilde{P}(x,y) f_i(x,y) - \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) f_i(x,y) \right] \\
    &= \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) \log P_w(y|x) + \sum\limits_{i=1}^n w_i \left[ \sum\limits_{x,y} \tilde{P}(x,y) f_i(x,y) - \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) f_i(x,y) \right] \\
    &= \sum\limits_{i=1}^n w_i \sum\limits_{x,y} \tilde{P}(x,y) f_i(x,y) + \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) \left[ \log P_w(y|x) - \sum\limits_{i=1}^n w_i f_i(x,y) \right] \\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \sum\limits_{i=1}^n w_i f_i(x,y) + \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) \left[ \log P_w(y|x) - \sum\limits_{i=1}^n w_i f_i(x,y) \right] \\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \sum\limits_{i=1}^n w_i f_i(x,y) + \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) \log \frac 1 {Z_w(x)} \\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \sum\limits_{i=1}^n w_i f_i(x,y) - \sum\limits_{x,y} \tilde{P}(x) P_w(y|x) \log Z_w(x) \\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \sum\limits_{i=1}^n w_i f_i(x,y) - \sum\limits_{x} \tilde{P}(x) \log Z_w(x)
\end{aligned}
$$

**结论**:
通过上边的求解过程，我们把原始问题: 求解$min_{P} \quad max_w \quad L(P,w)$  
转化为了求解 $max_w \quad  \Psi(w)$

## 3. 最大熵模型的一般形式
**概括下上面的步骤，可以这样表述**:  
1. (x,y)服从的条件概率为:
$$
    P_w(y|x) = \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {\sum\limits_y  exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)}
    = \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {Z_w(x)} \quad (1)
$$
2. 这个表达式中的参数w，可以通过最大化$\Psi(w)$来求解
$$
    \Psi(w) = \sum\limits_{x,y} \tilde{P}(x,y) \sum\limits_{i=1}^n w_i f_i(x,y) - \sum\limits_{x} \tilde{P}(x) \log Z_w(x)
$$

**最大似然估计**:  
前边提到过，上边的(1)式就是**最大熵模型**，接下来对**最大熵模型**进行**最大似然估计**  
首先统计训练数据的经验分布$\tilde{P}(x,y)$，条件概率$P(y|x)$的对数似然函数可以表示为:  
$$
\begin{aligned}
    l(P_w) &= \log \prod\limits_{x,y} P_w(y|x)^{\tilde{P}(x,y)} \\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \log P_w(y|x) \\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \log \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {Z_w(x)}\\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \sum\limits_{i=1}^n w_i f_i(x,y) - \sum\limits_{x,y} \tilde{P}(x,y) \log Z_w(x)\\
    &= \sum\limits_{x,y} \tilde{P}(x,y) \sum\limits_{i=1}^n w_i f_i(x,y) - \sum\limits_x \tilde{P}(x) \log Z_w(x)
\end{aligned}
$$

- 与$\Psi(w)$完全一致!!
- 所以最大化$\Psi(w)$，也就是 对模型进行**最大似然估计**  

**结论**:  
最后总结一下，最大熵模型的一般形式:
$$
    P_w(y|x) = \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {\sum\limits_y  exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)}
    = \frac {exp \left( \sum\limits_{i=1}^n w_i f_i(x,y) \right)} {Z_w(x)} \quad (1)
$$
> $f_i(x,y)$ 是特征函数，由用户指定，作用就是指定某些$P(y_i|x_i)$，直接使用经验分布，不需要模型去学习  
> $w_i$ 是特征的权值，是模型的参数  
- 模型的学习策略则是**最大似然估计**

## 4. 拟牛顿法

**todo**