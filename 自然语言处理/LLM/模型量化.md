# 模型量化

- paper
    1. LLM.int8 [paper](https://arxiv.org/abs/2208.07339)、 [参考博文](https://huggingface.co/blog/zh/hf-bitsandbytes-integration)
    2. QLoRA [paper](https://arxiv.org/abs/2305.14314)、 [参考博文](https://huggingface.co/blog/4bit-transformers-bitsandbytes)

## 一、8bit量化 (LLM.int8)

### 1、 向量量化，将向量中的每个浮点值映射为`Int8`
1. 零点量化 (zero-point quantization)
2. 最大绝对值量化 (absolute maximum quantization，absmax)
    - 例如，用absmax对向量 $(1.2, -0.5, -4.3, 2.4, 5.4)$ 进行量化
        1. 获取向量中的最大绝对值: 5.4
        2. 计算缩放因子，我们的目标需要将[-5.4, 5.4]之间的数，映射到[-127, 127]，因此缩放因子为 127/5.4=23.5
        3. 原始向量中的每个数值，乘以缩放因子，得到新向量 $(28, -12, -101, 56, 127)$
    - 反量化，恢复原向量
        1. 新向量中的每个数值，除以缩放因子，得到向量 $(1.2, -0.5, -4.3, 2.4, 5.4)$
### 2、矩阵乘法中的技巧
1. 逐行 或 逐列 进行量化
    > 例如 需要计算 $\mathbf A \cdot \mathbf B = \mathbf C$

    $$
    \mathbf A^{3*5} \cdot \mathbf B^{5*2} = 
    \begin{pmatrix}
        2 & 45 & -1 & 17 & -1\\
        0 & 12 & 3 & -63 & 2\\
        -1 & 37 & -1 & -83 & 0
    \end{pmatrix}
    \begin{pmatrix}
        -1 & 0\\
        2 & 0\\
        0 & -2\\
        3 & -2\\
        -1 & 2
    \end{pmatrix}\\
    $$

    1. $\mathbf A$ 逐列量化，$\mathbf B$ 逐行量化
    2. 量化后的矩阵，做矩阵乘法，得到 $\mathbf {out}$
    3. $\mathbf {out}$反量化，得到 $\mathbf C$
2. `离群特征`
    - 只对矩阵中的一部分向量进行量化，其余部分保持原来精度
    - 分解方式就是使用`离群特征`，例如我们选择一个阈值`6.0`作为离群值，矩阵乘法过程就这样更新:
        1. $\mathbf A$ 中1、3、5列，组成矩阵$\mathbf A_1$，2、4列中有元素超过`6.0`，保持不变，组成矩阵$\mathbf A_2$
        2. $\mathbf B$ 中1、3、5行，组成矩阵$\mathbf B_1$，相应地，2、4行保持不变，组成矩阵$\mathbf B_2$
        3. $\mathbf A_1$、$\mathbf B_1$量化后，矩阵乘法，得到 $\mathbf {out}_1$，反量化，得到$\mathbf C_1$
        4. $\mathbf A_2$、$\mathbf B_2$，直接矩阵乘法，得到 $\mathbf C_2$
        5. $\mathbf C_1 + \mathbf C_2 = \mathbf C$

3. 博文中的这张动图，一目了然

    ![Mixed-int8.gif](jpgs/Mixed-int8.gif) 

### 3、性能与速度
1. 性能
    - 论文中在OPT-175B模型、 BLOOM-176B模型上做了测试，性能下降为0，因此称为`零退化`
2. 速度
    - BLOOM-176B模型 使用LLM.int8()后，比FP16版本慢了大约 15% 到 23%，完全可接受
